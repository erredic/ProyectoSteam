{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceso del Archivo SteamGames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('SteamGames.json', lines=True)\n",
    "df = df.dropna(how='all')\n",
    "df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "\n",
    "def convert_to_float_or_zero(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return 0\n",
    "\n",
    "df['price'] = df['price'].apply(convert_to_float_or_zero)\n",
    "df['early_access'] = df['early_access'].replace({0.0: False, 1.0: True})\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['release_date'] = df['release_date'].replace('Soon..', pd.NaT)\n",
    "df['item_id'] = df['item_id'].fillna(0).astype('int64')\n",
    "\n",
    "df.to_csv('SteamGames.csv', index=False)\n",
    "df.to_parquet('SteamGames.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceso del Archivo UserReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateo\\AppData\\Local\\Temp\\ipykernel_17912\\3512060537.py:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['posted'] = pd.to_datetime(df['posted'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El análisis de sentimiento ha sido  guardado en 'UserReviews.csv' y 'UserReviews.parquet'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob  # asegurarse de tener instalada la biblioteca TextBlob previamente\n",
    "\n",
    "# Función para corregir y cargar cada línea del archivo 'australian_user_reviews.json' original\n",
    "def cargar_y_corregir_linea(linea):\n",
    "    # Reemplaza las comillas simples con dobles y corrige valores booleanos\n",
    "    linea_corregida = linea.replace(\"'\", '\"').replace('True', 'true').replace('False', 'false')\n",
    "    return json.loads(linea_corregida)\n",
    "\n",
    "# Lista para almacenar los datos desanidados\n",
    "data_list = []\n",
    "\n",
    "# Expresión regular para extraer números de la columna 'funny'\n",
    "numero_regex = re.compile(r'\\d+')\n",
    "\n",
    "# Lee el archivo 'australian_user_reviews.json' original, corrige y procesa cada línea\n",
    "with open('UserReviews.json', 'r', encoding='utf-8') as archivo_json:\n",
    "    for linea in archivo_json:\n",
    "        try:\n",
    "            entrada = cargar_y_corregir_linea(linea)\n",
    "            user_id = entrada['user_id']\n",
    "            user_url = entrada['user_url']\n",
    "            # Iteración sobre cada reseña\n",
    "            for reseña in entrada['reviews']:\n",
    "                # Extrae el número de la columna 'funny'\n",
    "                funny_valor = re.search(numero_regex, reseña.get('funny', ''))\n",
    "                if funny_valor:\n",
    "                    funny = int(funny_valor.group())\n",
    "                else:\n",
    "                    funny = None\n",
    "                \n",
    "                # Elimina 'Posted' de la columna 'posted'\n",
    "                posted = reseña.get('posted', '').replace('Posted ', '', 1)\n",
    "\n",
    "                reseña_dict = {\n",
    "                    'user_id': user_id,\n",
    "                    'user_url': user_url,\n",
    "                    'funny': funny,\n",
    "                    'posted': posted,\n",
    "                    'item_id': int(reseña.get('item_id', '')),  # Convierte a entero\n",
    "                    'helpful': reseña.get('helpful', ''),\n",
    "                    'recommend': reseña.get('recommend', ''),\n",
    "                    'review': reseña.get('review', '')  # Mantiene el texto original de la review\n",
    "                }\n",
    "                data_list.append(reseña_dict)\n",
    "        except json.JSONDecodeError as e:\n",
    "            None\n",
    "\n",
    "# Crea el DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Elimina la columna 'last_edited' si existe\n",
    "if 'last_edited' in df.columns:\n",
    "    df.drop(columns=['last_edited'], inplace=True) \n",
    "\n",
    "# Función para analizar el sentimiento de la reseña\n",
    "def analyze_sentiment(review):\n",
    "    if pd.isna(review) or not isinstance(review, str):\n",
    "        return 1  # Sentimiento neutral para reseñas faltantes o no legibles\n",
    "    else:\n",
    "        # Se emplea TextBlob para calcular la polaridad del sentimiento\n",
    "        polarity = TextBlob(review).sentiment.polarity\n",
    "        if polarity < 0:\n",
    "            return 0  # Sentimiento negativo\n",
    "        elif polarity == 0:\n",
    "            return 1  # Sentimiento neutral\n",
    "        else:\n",
    "            return 2  # Sentimiento positivo\n",
    "\n",
    "# Aplica la función analyze_sentiment a cada reseña y crea la nueva columna 'sentiment_analysis'\n",
    "df['sentiment_analysis'] = df['review'].apply(analyze_sentiment)\n",
    "\n",
    "# Convierte la columna 'posted' a tipo datetime\n",
    "df['posted'] = pd.to_datetime(df['posted'], errors='coerce')\n",
    "\n",
    "# Elimina la columna original 'review'\n",
    "df.drop(columns=['review'], inplace=True)\n",
    "\n",
    "# Guarda el DataFrame modificado en un nuevo archivo CSV\n",
    "df.to_csv('UserReviews.csv', index=False)\n",
    "\n",
    "# Guarda el DataFrame modificado en un nuevo archivo Parquet\n",
    "df.to_parquet('UserReviews.parquet', index=False)\n",
    "\n",
    "print(\"El análisis de sentimiento ha sido  guardado en 'UserReviews.csv' y 'UserReviews.parquet'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han guardado correctamente 'UsersItems.parquet' y 'UsersItems.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Función para cargar y corregir cada línea del archivo JSON original\n",
    "def cargar_y_corregir_linea(linea):\n",
    "    # Cambia comillas simples por comillas dobles\n",
    "    linea_corregida = linea.replace(\"'\", '\"')\n",
    "    return json.loads(linea_corregida)\n",
    "\n",
    "# Lista para almacenar los datos desanidados\n",
    "data_list = []\n",
    "\n",
    "# Lee el archivo JSON original, corrige y procesa cada línea\n",
    "with open('UsersItems.json', 'r', encoding='utf-8') as archivo_json:\n",
    "    for linea in archivo_json:\n",
    "        try:\n",
    "            entrada = cargar_y_corregir_linea(linea)\n",
    "            # Obtén datos del usuario\n",
    "            user_id = entrada['user_id']\n",
    "            items_count = entrada['items_count']\n",
    "            steam_id = entrada['steam_id']\n",
    "            user_url = entrada['user_url']\n",
    "            # Itera sobre cada ítem\n",
    "            for item in entrada['items']:\n",
    "                # Crea un diccionario para cada ítem y agrégalo a la lista\n",
    "                item_dict = {\n",
    "                    'user_id': user_id,\n",
    "                    'items_count': items_count,\n",
    "                    'steam_id': steam_id,\n",
    "                    'user_url': user_url,\n",
    "                    'item_id': item['item_id'],\n",
    "                    'item_name': item['item_name'],\n",
    "                    'playtime_forever': item['playtime_forever'],\n",
    "                    'playtime_2weeks': item['playtime_2weeks']\n",
    "                }\n",
    "                data_list.append(item_dict)\n",
    "        except json.JSONDecodeError:\n",
    "            None\n",
    "\n",
    "# Crea el DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Guarda el DataFrame en un nuevo archivo CSV\n",
    "df.to_csv('UsersItems.csv', index=False)\n",
    "\n",
    "# Guarda el DataFrame en un nuevo archivo Parquet\n",
    "df.to_parquet('UsersItems.parquet', index=False)\n",
    "\n",
    "print(\"Se han guardado correctamente 'UsersItems.parquet' y 'UsersItems.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
